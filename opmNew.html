<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>OPM Viz - Visualization Systems for Student Reflection</title>
    <style>
        /* --- New Sidebar and Layout Styles --- */
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            background-color: #ffffff;
            background-image: 
                linear-gradient(rgba(200, 200, 200, 0.15) 1px, transparent 1px),
                linear-gradient(90deg, rgba(200, 200, 200, 0.15) 1px, transparent 1px);
            background-size: 40px 40px;
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Helvetica Neue', Arial, sans-serif;
            font-size: 1.05rem;
            line-height: 1.6;
            color: #1a1a1a;
            margin: 0;
            display: flex;
            min-height: 100vh;
        }
        nav {
            width: 220px;
            padding: 2rem;
            border-right: 1px solid rgba(200, 200, 200, 0.3);
            flex-shrink: 0;
            background-color: rgba(255, 255, 255, 0.95);
            backdrop-filter: blur(10px);
        }
        nav a {
            display: block;
            margin-bottom: 1rem;
            color: #1a1a1a;
            text-decoration: underline;
            cursor: pointer;
            transition: color 0.2s ease;
        }
        nav a:hover {
            text-decoration: none;
            color: #666;
        }
        .nav-logo {
            font-weight: 600;
            margin-bottom: 2rem;
            text-decoration: none;
            cursor: pointer;
            font-size: 1.3rem;
            color: #1a1a1a;
            transition: color 0.2s ease;
        }
        .nav-logo:hover {
            color: #666;
        }
        #project-links-container {
            margin-top: 0.5rem;
            padding-left: 1rem;
            border-left: 1px solid #eee;
        }
        .project-link {
            font-size: 1rem;
        }
        main {
            flex-grow: 1;
            overflow-y: auto;
            height: 100vh;
            background-color: transparent;
        }
        .hidden {
            display: none;
        }
        @media (max-width: 992px) {
            body {
                flex-direction: column; 
            }
            main {
                height: auto;
            }
            nav {
                width: 100%; 
                padding: 1rem;
                border-right: none; 
                border-bottom: 1px solid #ddd; 
                box-sizing: border-box;
            }
            .nav-container {
                display: flex;
                justify-content: center;
                gap: 1.5rem;
                flex-wrap: wrap;
            }
            .nav-logo {
                display: none;
            }
            nav a {
                margin-bottom: 0;
            }
            #project-links-container {
                width: 100%;
                text-align: center;
                padding-left: 0;
                border-left: none;
                margin-top: 1rem;
            }
        }

        /* --- Case Study Styles --- */
        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 3rem 2rem;
        }
        h1 {
            font-size: 2.8rem;
            font-weight: 700;
            margin-bottom: 1rem;
            color: #1a1a1a;
            line-height: 1.2;
        }
        h2 {
            font-size: 2rem;
            font-weight: 700;
            margin-top: 3rem;
            margin-bottom: 1.5rem;
            color: #1a1a1a;
        }
        h3 {
            font-size: 1.5rem;
            font-weight: 600;
            margin-top: 2rem;
            margin-bottom: 1rem;
            color: #1a1a1a;
        }
        p {
            margin-bottom: 1.5rem;
            color: #333;
        }
        .project-meta {
            font-size: 1.1rem;
            color: #666;
            margin-bottom: 2rem;
        }
        .badge {
            display: inline-block;
            padding: 0.4rem 1rem;
            background-color: #f0f0f0;
            border-radius: 20px;
            font-size: 0.9rem;
            margin-right: 0.5rem;
            margin-bottom: 0.5rem;
        }
        img {
            max-width: 100%;
            height: auto;
            border-radius: 12px;
            margin: 2rem 0;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
        }
        ul {
            margin-left: 2rem;
            margin-bottom: 1.5rem;
        }
        li {
            margin-bottom: 0.5rem;
        }
        
        @media (max-width: 768px) {
            .container { padding: 0 1rem; }
            h1 { font-size: 2rem; }
            h2 { font-size: 1.5rem; }
        }
    </style>
</head>
<body>

        <nav>
            <a href="index.html" class="nav-logo">Sai Maram</a>
            <div class="nav-container">
                <a href="index.html">Home</a>
                <a href="https://siddu1998.github.io/cv.pdf" target="_blank">Resume</a>
            </div>
        </nav>

    <main>
        <div class="container">
            <h1>OPM Viz: Bridging Gameplay Data and Learning Reflection</h1>
            <div class="project-meta">
                <span class="badge">ACM CHI 2024</span>
                <span class="badge">Educational Games</span>
                <span class="badge">Design-Based Research</span>
            </div>
            
            <p>Educational games generate massive amounts of gameplay data—every decision, every strategy, every moment of struggle or breakthrough. But when students finish a level, where does that data go? Usually, nowhere. The game records it, but students never see it again. They don't know how their approach compared to their peers, where they could improve, or what strategies might be more efficient.</p>
            
            <p>This case study documents the development of OPM Viz, a visualization system for the 'Parallel' educational game that transforms gameplay data into learning opportunities. Rather than letting valuable performance data disappear into the void, OPM Viz makes it accessible, comparable, and actionable—turning every play session into a reflective learning experience.</p>

            <h2>The Problem</h2>
            <p><strong>Educational games capture rich data, but students can't access it:</strong> Games like 'Parallel' (which teaches parallel programming) record detailed information about how students approach problems: which strategies they use, where they struggle, how their solutions compare to optimal approaches. But this data typically lives in logs that only researchers see. Students are left wondering: "Was my solution good? How did others solve this? What could I do better?"</p>
            
            <p><strong>The missed learning opportunity:</strong> Research in learning sciences shows that reflection and peer comparison significantly enhance learning. Students learn by analyzing their own performance, seeing how others approached the same challenge, and identifying specific areas for improvement. Educational games generate the data needed for this reflection, but don't provide tools to visualize it.</p>
            
            <p><strong>The practical challenge:</strong> Existing educational games often include performance dashboards showing scores or completion rates, but these don't reveal the "why" behind performance. A student might know they took 50 steps to complete a level, but not understand which steps were inefficient or how a peer solved it in 20 steps with a different strategy.</p>

            <h2>My Approach</h2>
            <p><strong>As Lead UX Researcher and Designer</strong>, I conducted a 21-month Design-Based Research project to create and validate OPM Viz:</p>
            
            <ul>
                <li><strong>Conducted instructor focus groups:</strong> Worked with 2 parallel programming instructors who analyzed student gameplay recordings to understand how experts identify learning moments</li>
                <li><strong>Led student playtesting:</strong> Observed 10 students playing 'Parallel' and conducted semi-structured interviews to identify core needs</li>
                <li><strong>Applied thematic analysis:</strong> Coded qualitative data to understand patterns in student struggles and desires</li>
                <li><strong>Designed interactive visualization system:</strong> Built OPM Viz enabling peer comparison, metrics viewing, and synchronized replay</li>
                <li><strong>Integrated with 'Parallel':</strong> Seamlessly connected the visualization with the game's existing platform</li>
                <li><strong>Evaluated learning impact:</strong> Conducted usability study with 8 students using think-aloud protocol and interviews</li>
            </ul>

            <h2>Key Outcomes</h2>
            <ul>
                <li><strong>Students identified specific inefficiencies</strong> in their parallel programming strategies</li>
                <li><strong>Improved self-assessment and metacognition</strong> through comparative visualization</li>
                <li><strong>Sparked curiosity about alternative approaches</strong> to problem-solving</li>
                <li><strong>Demonstrated successful reflection:</strong> Students actively used the system to analyze their gameplay</li>
                <li><strong>Published at ACM CHI 2024</strong>—the premier HCI conference</li>
                <li><strong>Novel Open Player Model approach:</strong> Applied Open Learner Model principles to dynamic gameplay contexts</li>
            </ul>

            <h2>The Challenge: From Data to Learning</h2>
            <p>Educational games like 'Parallel', which teaches parallel programming concepts, generate vast amounts of player data. However, a significant gap exists: how can this data be effectively visualized to help students reflect on their own learning process and understand the strategies used by their peers?</p>

            <p>Existing tools often lack features specifically designed to foster reflective learning. Our core challenge was to design a visualization system that moves beyond simple data presentation to actively guide students in analyzing gameplay, comparing strategies, and ultimately deepening their understanding of complex concepts taught through the game.</p>

            <h2>Understanding the Users: Instructors & Students</h2>
            <p>To ensure our solution was grounded in real needs, we employed a Design-Based Research approach, incorporating UX methods to understand both instructor goals and student expectations.</p>

            <div class="image-container">
                <img src="temporary/images/Frame 10 (2) (1).png" alt="UXR pipeline diagram showing Understand, Design, Evaluate process">
                <div class="image-caption">UXR pipeline adopted for this project.</div>
            </div>

            <h3>Instructor Focus Groups: Learning from Expert Practice</h3>
            <p>Before designing the visualization, we needed to understand how experts actually use gameplay data to support learning. We conducted workshops with two experienced parallel programming instructors, asking them to analyze anonymized student gameplay recordings from 'Parallel'.</p>
            
            <p><strong>The process:</strong> Instructors watched recordings of students playing levels, identified different strategies students used, ranked performance, and pinpointed specific moments where reflection would be valuable. Through observation and think-aloud protocol, we documented how experts naturally analyze gameplay data.</p>

            <p><strong>Key insights emerged from how instructors naturally worked:</strong></p>
            <ul>
                <li><strong>Chunking gameplay into meaningful segments:</strong> Instructors didn't analyze gameplay as continuous streams—they broke it into conceptual chunks. One instructor observed, <em>"Steps 2 and 3, that's where the student is trying to figure out the Switch mechanism."</em> This revealed that effective visualization needs to segment gameplay around learning concepts, not just chronological steps.</li>
                <li><strong>Spatial context matters:</strong> Instructors constantly connected gameplay actions to specific game areas and programming concepts. They'd note, "This is happening in the synchronization zone," linking spatial gameplay to abstract parallel programming concepts.</li>
                <li><strong>Comparative analysis drives insight:</strong> Instructors rarely analyzed a single student in isolation. They consistently compared strategies across students, noting things like "This student used a mutex here, while this one avoided it entirely," using comparison to highlight efficiency or alternative approaches.</li>
                <li><strong>Performance metrics grounded in learning:</strong> When ranking students, instructors didn't just count steps or time. They evaluated based on core parallel programming concepts: Did students identify critical sections? Did they minimize critical section size? Did they understand concurrency patterns?</li>
            </ul>

            <h3>Student Playtesting: Understanding Learner Needs</h3>
            <p>To understand what students actually need from a visualization system, we observed 10 students playing 'Parallel' and conducted semi-structured interviews following their gameplay. This revealed a significant gap between what games currently offer and what learners actually need.</p>
            
            <p><strong>What we observed:</strong> Students played levels, sometimes struggling for extended periods, sometimes finding elegant solutions quickly. After completion, we asked about their experience: What was hard? How did they know if their solution was good? What would help them improve? Through thematic analysis of interview transcripts and gameplay observations, three core needs emerged.</p>

            <h4>Key Insights from Students:</h4>
            <ol>
                <li><strong>Desire for efficiency improvement:</strong> Players weren't satisfied with just completing levels—they wanted to know if their solutions were efficient. One student expressed frustration: "I finished it, but I have no idea if there's a better way. Am I using ten steps when I could use five?" Students craved ways to identify inefficiencies and learn from more optimal peer strategies.</li>
                <li><strong>Need for multi-scale comparison:</strong> Students wanted to compare their gameplay with peers, but at different levels of detail. Sometimes they needed a high-level overview: "Did I take more steps overall?" Other times they needed granular step-by-step comparison: "What did they do differently at step 15?" The visualization needed to support both zoomed-out summaries and detailed moment-by-moment analysis.</li>
                <li><strong>Seeking guidance without giving up:</strong> When stuck, students wanted help, but didn't want complete answers handed to them. They appreciated hints or alternative solution paths—ways to nudge them forward without defeating the challenge. After completing levels, they also valued exploring different valid approaches, understanding that there were multiple ways to solve the same problem.</li>
            </ol>
            
            <p><strong>Why this mattered for design:</strong> These insights directly shaped OPM Viz's features. The need for efficiency comparison led to peer performance metrics. The desire for multi-scale views informed our "overview first, then zoom and filter" approach. The want for guidance without answers inspired our reflection prompts—questions that guided analysis without revealing solutions.</p>

            <h2>Designing the Visualization System</h2>
            <p>Guided by insights from instructors and students, and utilizing Shneiderman's Visual Information-Seeking Mantra ("Overview first, zoom and filter, then details-on-demand") as a framework, we designed and developed the OPM Viz system.</p>

            <p>Key design goals included:</p>
            <ul>
                <li>Providing an overview comparing a student's performance against the community</li>
                <li>Allowing users to filter and select specific peer playtraces for deeper comparison</li>
                <li>Offering a synchronized, detailed side-by-side view of playtraces</li>
                <li>Incorporating metrics relevant to parallel programming efficiency</li>
                <li>Suggesting moments for reflection based on common patterns or deviations</li>
            </ul>

            <div class="image-container">
                <img src="temporary/images/Group 107 (4).png" alt="Screenshot of the OPM Viz visualization system interface">
                <div class="image-caption">The OPM Viz Visualization System Interface.</div>
            </div>

            <h2>The Solution: OPM Viz</h2>
            <p>OPM Viz is an interactive visualization system designed to integrate seamlessly with the 'Parallel' serious game. It empowers students to reflect on their gameplay, compare strategies with peers, and gain deeper insights into parallel programming concepts.</p>

            <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 2rem; margin: 2rem 0;">
                <div>
                    <iframe src="https://www.youtube.com/embed/sJTFw3Qix5o?si=xUFYlOV8RAiHKTvu" frameborder="0" allowfullscreen title="Explanation of the final visualization system" style="width: 100%; aspect-ratio: 16/9; border-radius: 12px; box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);"></iframe>
                    <p style="margin-top: 0.5rem; text-align: center; color: #666; font-size: 0.95rem;">Explaining the features of the OPM Viz system.</p>
                </div>
                <div>
                    <iframe src="https://www.youtube.com/embed/MXeTHQlgcT8?si=38yGfgb_BQdqDCre" frameborder="0" allowfullscreen title="Development process and algorithms" style="width: 100%; aspect-ratio: 16/9; border-radius: 12px; box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);"></iframe>
                    <p style="margin-top: 0.5rem; text-align: center; color: #666; font-size: 0.95rem;">Overview of the development process and algorithms.</p>
                </div>
            </div>

            <p>The system allows students to:</p>
            <ul>
                <li>View their own performance metrics</li>
                <li>Compare their solution path against anonymized peers</li>
                <li>Filter peers based on performance or specific strategies</li>
                <li>Replay their own and selected peers' games side-by-side</li>
                <li>Identify key differences and potential areas for improvement</li>
            </ul>

            <h2>Evaluation: Does it Foster Reflection?</h2>
            <p>Could OPM Viz actually prompt the kind of reflection and learning we designed it for? To answer this, we conducted an evaluative study with 8 student participants who had used 'Parallel' in a previous course.</p>
            
            <p><strong>The evaluation method:</strong> After playing levels in 'Parallel', participants used OPM Viz to explore their own gameplay data compared to anonymized peers. We employed think-aloud protocol—asking participants to verbalize their thoughts as they used the system. Following the session, we conducted semi-structured interviews probing deeper into their experience and what they learned.</p>

            <p><strong>Our analysis focused on three questions:</strong></p>
            <ul>
                <li>Did students actually use the system's features to compare their strategies with peers?</li>
                <li>Did using the system prompt reflection on their own performance and learning?</li>
                <li>What specific insights or learning moments did the visualization enable?</li>
            </ul>

            <div class="image-container">
                <img src="temporary/images/Group 749 (1).png" alt="Thematic analysis results showing student interactions">
                <div class="image-caption">Thematic map illustrating how students used OPM Viz for reflection and learning.</div>
            </div>

            <h4>Key Findings from Evaluation:</h4>
            <ul>
                <li><strong>Facilitated active comparison:</strong> Participants consistently used the system to compare their strategies with anonymized peers. One student noted, "I thought my solution was good until I saw someone did it in half the steps. Now I'm curious how." The visual comparison didn't just show differences—it prompted students to analyze why.</li>
                <li><strong>Identified specific inefficiencies:</strong> Rather than vague feelings of "maybe I could do better," students identified concrete areas where their approaches were less efficient. They'd pinpoint moments: "Oh, I see—I backtracked here three times, but this student solved it without backtracking."</li>
                <li><strong>Sparked conceptual curiosity:</strong> Exploring different solutions through the system encouraged students to think beyond "getting it done" to understanding the underlying programming concepts. A student observed, "These two solutions both work, but they're using different synchronization patterns. I want to understand why."</li>
                <li><strong>Supported calibrated self-assessment:</strong> Participants used comparative data to accurately gauge their own understanding. Rather than over- or under-estimating their performance, they developed realistic views of where they stood relative to their peers and where they needed to improve.</li>
                <li><strong>Highlighted design trade-offs:</strong> Observing different strategies helped students understand that parallel programming involves trade-offs. One solution might be simpler but less efficient; another might be faster but harder to understand. Students began thinking about these design decisions.</li>
            </ul>

            <p><strong>Overall impact:</strong> The evaluation confirmed that OPM Viz successfully prompted the kind of reflection we designed it for. Students didn't just passively view their data—they actively compared, analyzed, questioned, and learned. The system made gameplay data not just visible, but actionable for learning.</p>
            
            <p><strong>What made it effective:</strong> The key was enabling comparison across multiple dimensions simultaneously. Students could see performance metrics (steps, time) alongside visual replays of actual gameplay. They could compare at overview level ("I'm in the top third") and dive into details ("At step 7, they took a different path"). This multi-scale, multi-modal comparison is what enabled genuine reflection.</p>

            <h2>Impact and Contributions</h2>
            <p>This project demonstrates the potential of integrating player-facing visualization systems, informed by Open Learner Model principles, into serious games to enhance learning.</p>

            <div class="card">
                <h4>Key Contributions:</h4>
                <ul>
                <li><strong>Bridging OLMs and Games:</strong> Introduced an Open Player Model approach, adapting OLM principles for the dynamic context of serious games</li>
                <li><strong>Learning-Focused Visualization:</strong> Designed and validated a player-facing visualization system prioritizing reflection and learning over purely aesthetic goals</li>
                <li><strong>Enhancing 'Parallel':</strong> Provided a novel tool for the established 'Parallel' research platform, enabling new avenues for studying game-based learning</li>
                <li><strong>Published Research:</strong> Shared findings and system design with the academic community via publication at ACM CHI 2024</li>
                </ul>
            </div>

            <p>The positive evaluation results and academic recognition underscore the value of this user-centered approach to designing learning support tools within educational games.</p>

            <h2>Conclusion</h2>
            <p>The OPM Viz project successfully demonstrated how thoughtful visualization design can bridge the gap between gameplay data and meaningful learning reflection. By centering the design process around both instructor expertise and student needs, we created a system that not only presents data but actively facilitates the kind of comparative analysis and reflection that leads to deeper understanding.</p>

            <p>This work contributes to the growing field of learning analytics and educational technology, showing how UX research methods can inform the design of tools that truly support learning rather than simply displaying information.</p>

            <!-- Skills Demonstrated -->
            <div class="key-finding" style="margin-top: 3rem;">
                <h4>Skills & Methods Demonstrated</h4>
                <p><strong>Research:</strong> Design-Based Research • Focus Groups • Usability Testing • Thematic Analysis • User Research</p>
                <p><strong>Design:</strong> Visualization Design • Information Architecture • Interaction Design • Educational Technology • Prototyping</p>
                <p><strong>Specialized:</strong> Learning Analytics • Educational Games • Reflection Systems • Comparative Analysis • Data Visualization</p>
                <p><strong>Impact:</strong> Academic Publishing • Iterative Development • Cross-Functional Collaboration</p>
            </div>
        </div>

        <footer class="footer">
            <p>&copy; 2024 Sai Maram. Case Study.</p>
            <p><a href="./index.html">Back to Portfolio</a></p>
        </footer>
    </main>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const portfolioToggle = document.getElementById('portfolio-toggle');
            const projectLinksContainer = document.getElementById('project-links-container');
            const portfolioIndicator = document.getElementById('portfolio-indicator'); 

            if (portfolioToggle) {
                portfolioToggle.addEventListener('click', function() {
                    projectLinksContainer.classList.toggle('hidden');
                    if (projectLinksContainer.classList.contains('hidden')) {
                        portfolioIndicator.textContent = '+';
                    } else {
                        portfolioIndicator.textContent = '-';
                    }
                });
            }
        });

        function showLockedMessage() {
            alert("This case study is under NDA and cannot be shared publicly. Please contact me directly for more information about my work at Microsoft/Xbox.");
        }

        function showComingSoon() {
            alert("This project case study is currently being developed. Please check back soon!");
        }
    </script>
</body>
</html>