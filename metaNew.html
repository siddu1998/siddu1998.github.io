<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Reinventing Facebook's Home - UX Case Study</title>
    <style>
        /* --- New Sidebar and Layout Styles --- */
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            background-color: #ffffff;
            background-image: 
                linear-gradient(rgba(200, 200, 200, 0.15) 1px, transparent 1px),
                linear-gradient(90deg, rgba(200, 200, 200, 0.15) 1px, transparent 1px);
            background-size: 40px 40px;
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Helvetica Neue', Arial, sans-serif;
            font-size: 1.05rem;
            line-height: 1.6;
            color: #1a1a1a;
            margin: 0;
            display: flex;
            min-height: 100vh;
        }
        nav {
            width: 220px;
            padding: 2rem;
            border-right: 1px solid rgba(200, 200, 200, 0.3);
            flex-shrink: 0;
            background-color: rgba(255, 255, 255, 0.95);
            backdrop-filter: blur(10px);
        }
        nav a {
            display: block;
            margin-bottom: 1rem;
            color: #1a1a1a;
            text-decoration: underline;
            cursor: pointer;
            transition: color 0.2s ease;
        }
        nav a:hover {
            text-decoration: none;
            color: #666;
        }
        .nav-logo {
            font-weight: 600;
            margin-bottom: 2rem;
            text-decoration: none;
            cursor: default;
            font-size: 1.3rem;
            color: #1a1a1a;
        }
        #project-links-container {
            margin-top: 0.5rem;
            padding-left: 1rem;
            border-left: 1px solid #eee;
        }
        .project-link {
            font-size: 1rem;
        }
        main {
            flex-grow: 1;
            overflow-y: auto;
            height: 100vh;
            background-color: transparent;
        }
        .hidden {
            display: none;
        }
        @media (max-width: 992px) {
            body {
                flex-direction: column; 
            }
            main {
                height: auto;
            }
            nav {
                width: 100%; 
                padding: 1rem;
                border-right: none; 
                border-bottom: 1px solid #ddd; 
                box-sizing: border-box;
            }
            .nav-container {
                display: flex;
                justify-content: center;
                gap: 1.5rem;
                flex-wrap: wrap;
            }
            .nav-logo {
                display: none;
            }
            nav a {
                margin-bottom: 0;
            }
            #project-links-container {
                width: 100%;
                text-align: center;
                padding-left: 0;
                border-left: none;
                margin-top: 1rem;
            }
        }

        /* --- Case Study Styles --- */
        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 3rem 2rem;
        }
        h1 {
            font-size: 2.8rem;
            font-weight: 700;
            margin-bottom: 1rem;
            color: #1a1a1a;
            line-height: 1.2;
        }
        h2 {
            font-size: 2rem;
            font-weight: 700;
            margin-top: 3rem;
            margin-bottom: 1.5rem;
            color: #1a1a1a;
        }
        h3 {
            font-size: 1.5rem;
            font-weight: 600;
            margin-top: 2rem;
            margin-bottom: 1rem;
            color: #1a1a1a;
        }
        p {
            margin-bottom: 1.5rem;
            color: #333;
        }
        .project-meta {
            font-size: 1.1rem;
            color: #666;
            margin-bottom: 2rem;
        }
        .badge {
            display: inline-block;
            padding: 0.4rem 1rem;
            background-color: #f0f0f0;
            border-radius: 20px;
            font-size: 0.9rem;
            margin-right: 0.5rem;
            margin-bottom: 0.5rem;
        }
        img {
            max-width: 100%;
            height: auto;
            border-radius: 12px;
            margin: 2rem 0;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
        }
        ul {
            margin-left: 2rem;
            margin-bottom: 1.5rem;
        }
        li {
            margin-bottom: 0.5rem;
        }
        
        @media (max-width: 768px) {
            .container { padding: 0 1rem; }
            h1 { font-size: 2rem; }
            h2 { font-size: 1.25rem; }
            .hero-meta { flex-direction: column; gap: 0.5rem; }
            .overview-grid, .pros-cons { grid-template-columns: 1fr; }
        }
    </style>
</head>
<body>

        <nav>
            <div class="nav-logo">Sai Maram</div>
            <div class="nav-container">
                <a href="index.html">Home</a>
                <a href="https://siddu1998.github.io/cv.pdf" target="_blank">Resume</a>
            </div>
        </nav>

    <main>
        <div class="container">
            <h1>Reinventing Facebook's Home: Exploring Future Opportunities</h1>
            <div class="project-meta">
                <span class="badge">Meta Internship 2022</span>
                <span class="badge">Generative Research</span>
                <span class="badge">1B+ User Impact</span>
            </div>
            
            <p>Facebook's Home feed is one of the most used interfaces in the world—billions of people start their day scrolling through it. But by 2022, younger users were reporting that it felt "out of touch" with how they lived their lives. The feed showed content randomly, without considering what users needed in different moments: commuter updates during their morning commute, connection with friends after work, or inspiration during creative blocks.</p>
            
            <p>This case study documents my work as the sole UX Research Intern on Facebook's Top of Home team, where I led generative research to understand how the feed could evolve for the future. With limited traditional research methods available for exploring "what if" scenarios, I developed two novel research approaches that would reveal how users wanted to engage with Facebook across different moments and emotional states.</p>

            <h2>The Problem</h2>
            <p><strong>Facebook needed to evolve to stay relevant with younger users:</strong> By 2022, Facebook faced a critical challenge: its core demographic was aging, while younger users (Gen Z and millennials) were spending more time on TikTok, Instagram, and other platforms. The Facebook feed felt generic, showing the same content at 8am as it did at 8pm—ignoring that users have different needs, moods, and contexts throughout their day.</p>
            
            <p><strong>The feed lacked temporal and emotional context:</strong> Traditional feeds show content based on relevance and recency, but they don't consider <em>when</em> content is most useful or <em>how</em> users feel when they open the app. A weather update might be valuable first thing in the morning, but not at 9pm. An inspirational quote might resonate when someone's feeling unmotivated, but feel trivial when they're celebrating.</p>
            
            <p><strong>The research challenge:</strong> Product teams wanted to understand future opportunities, but traditional user research excels at testing existing concepts, not generating new ones. How do you research something that doesn't exist yet? How do you understand what users might want before they can articulate it?</p>

            <h2>My Approach</h2>
            <p><strong>As the sole UX Research Intern</strong>, I led generative research to identify future opportunities for Facebook Home:</p>
            
            <ul>
                <li><strong>Developed two novel research methods:</strong> Created "Time Loop" for understanding temporal needs and "Feeling Cues" for emotional contexts—approaches tailored for exploring future scenarios</li>
                <li><strong>Conducted 15+ in-depth user interviews</strong> with diverse users (students, working professionals, parents) to uncover latent needs and desires</li>
                <li><strong>Created 21 experience prototypes</strong> in Figma based on research insights, translating abstract needs into concrete design concepts</li>
                <li><strong>Synthesized findings across methods</strong> to identify patterns and themes</li>
                <li><strong>Presented insights to product teams</strong> to influence roadmap and strategic direction</li>
            </ul>

            <h2>Key Outcomes</h2>
            <ul>
                <li><strong>1B+ users impacted</strong> through Meta-Spotify integration and Facebook Sports cards—features directly informed by this research</li>
                <li><strong>Two novel research methods:</strong> Time Loop and Feeling Cues became reusable frameworks for generative research</li>
                <li><strong>21 forward-looking prototypes</strong> informed product direction beyond what ultimately shipped</li>
                <li><strong>Strategic impact:</strong> Insights shaped Facebook's understanding of contextual and emotional engagement</li>
                <li><strong>Methodological contribution:</strong> Published methods that other researchers could apply to future-focused projects</li>
            </ul>

            <img src="Group 11.png" alt="Some design outcomes from the project">

            <h2>Why Traditional Research Methods Fell Short</h2>
            <p>Traditional user research excels at answering questions like "Do users understand this interface?" or "Would they click this button?" But when exploring future opportunities for a product as mature and universal as Facebook Home, these methods hit limitations.</p>
            
            <p><strong>The challenge:</strong> Users are anchored to their current experience. If you ask them "What do you want from Facebook Home?", they'll describe incremental improvements to what exists. But Facebook needed to understand entirely new paradigms—content organized by emotional state, feeds that adapt to time of day, features that anticipate needs rather than react to them.</p>
            
            <p><strong>Why standard interviews don't work for generative research:</strong> Direct questions produce predictable answers. Users don't know what they'd want because they've never experienced it. They need to experience scenarios before they can evaluate them. This required methods that could simulate future experiences, not just ask about current ones.</p>

            <h2>Developing Novel Research Methods</h2>
            <p>Given these limitations, I needed to develop research approaches specifically designed for exploring future experiences. Drawing from temporal research, emotion mapping, and contextual inquiry, I created two complementary methods that could uncover latent needs through experiential simulation rather than direct questioning.</p>
            
            <p><strong>Confidentiality note:</strong> Due to NDA requirements, I cannot share specific insights or prototypes from this work. However, this case study focuses on the methodological innovations—the research approaches I developed that could be valuable for other future-focused projects.</p>

            <h2>The Two Research Methods</h2>
            <p>To uncover forward-looking user needs related to context (time) and emotion, I developed and applied the following two methods:</p>

            <h3>Method 1: Time Loop - Understanding Temporal Needs</h3>
            <p><strong>The core insight:</strong> Users don't need the same content at 8am as they do at 8pm. A weather update is valuable first thing in the morning—less so at night. News updates might be important during lunch breaks—not during bedtime. The Time Loop method explored these temporal patterns in user needs.</p>
            
            <p><strong>How it worked:</strong> Rather than asking "What do you want from Facebook?", I used visual cues to simulate different times of day: morning alarm, commute, midday break, evening wind-down. For each scenario, participants imagined opening Facebook and described what would be most helpful.</p>
            
            <p><strong>Example prompt:</strong> "It's 7:30am, you just woke up, and you open Facebook before starting your day. What would you ideally like to see first?"</p>
            
            <p>This approach revealed patterns that direct questioning wouldn't: participants consistently wanted practical, action-oriented content in the morning (weather, commute status, calendar reminders) and emotional, connection-focused content in the evening (friend updates, shared experiences, entertainment).</p>

            <img src="temporary/images/time_loop.png" alt="Visual cues for different times of day used in the Time Loop method">

            <h3>Method 2: Feeling Cues - Connecting Content to Emotion</h3>
            <p><strong>The core insight:</strong> Facebook serves emotional needs beyond just information or entertainment. Users come to Facebook when they're feeling lonely, seeking inspiration, wanting to relax, or needing motivation. The Feeling Cues method explored how content could align with these emotional states.</p>
            
            <p><strong>How it worked:</strong> I presented participants with visual cues representing different emotional states or feelings (e.g., connected, informed, inspired, nostalgic, motivated). For each feeling, we explored what content on Facebook Home could evoke or support that emotion.</p>
            
            <p><strong>Example prompt:</strong> "When you're feeling disconnected or lonely, what could Facebook Home display that would help you feel connected again?"</p>
            
            <p>This revealed emotional content patterns: participants associated "connected" with close friends' updates and family photos; "informed" with news from trusted sources and educational content; "inspired" with creative content and achievement stories. These associations weren't abstract—they linked specific content types to specific emotional outcomes.</p>
            
            <img src="temporary/images/keyword_cues.png" alt="Visual cues for different emotional states used in the Feeling Cues method">

            <h2>Why These Methods Worked</h2>
            <p>Both methods shared key characteristics that made them effective for generative research:</p>
            
            <ul>
                <li><strong>Visual simulation over direct questioning:</strong> Instead of asking users to describe future experiences they'd never had, these methods simulated scenarios they could evaluate</li>
                <li><strong>Context-rich scenarios:</strong> By grounding prompts in specific contexts (time of day, emotional state), participants could imagine concrete, contextualized desires</li>
                <li><strong>Pattern identification across users:</strong> While individual responses varied, consistent patterns emerged across participants—enabling identification of universal needs</li>
                <li><strong>Future-focused by design:</strong> These methods broke users out of current usage patterns and invited them to imagine entirely different experiences</li>
            </ul>

            <h2>Research Impact & Outcomes</h2>
            <p>The Time Loop and Feeling Cues methods generated rich insights that directly informed product development. While specific findings remain confidential due to NDA, the research contributed to features that reached over 1 billion users.</p>
            
            <p><strong>Features informed by this research:</strong> The Sports scorecard and Spotify connect features—currently deployed across Meta products—emerged directly from patterns identified through these methods. For example, temporal patterns revealed that users wanted sports updates during specific times of day, while emotional context research identified music as content that supported multiple emotional states (relaxation, motivation, celebration).</p>
            
            <p><strong>Beyond shipped features:</strong> The 21 prototypes created from this research informed product direction beyond what ultimately launched, shaping Facebook's understanding of contextual and emotional engagement for future development.</p>

            <h2>Methodological Contributions</h2>
            <p>Beyond the immediate product impact, this work contributed methodological innovations for generative research:</p>
            
            <ul>
                <li><strong>Time Loop method:</strong> A reusable framework for understanding temporal patterns in user needs that other researchers could apply to future-focused projects</li>
                <li><strong>Feeling Cues method:</strong> A systematic approach to mapping emotional content associations that could guide emotionally-aware interface design</li>
                <li><strong>Visual cue approach:</strong> Demonstrated how visual simulation could overcome limitations of direct questioning in generative research</li>
                <li><strong>Hybrid methodology:</strong> Showed how combining temporal and emotional lenses could provide comprehensive understanding of user needs</li>
            </ul>

            <h2>Key Learnings</h2>
            <p><strong>For future-focused research:</strong> Generative research requires patience and systematic methodology. Users can't articulate needs for experiences they've never had—research methods must simulate future scenarios rather than asking about abstract possibilities.</p>
            
            <p><strong>Multiple perspectives matter:</strong> Combining temporal (Time Loop) and emotional (Feeling Cues) lenses revealed different aspects of user needs. Neither method alone would have provided complete understanding—together they created a comprehensive picture of how users wanted to engage with Facebook across contexts.</p>
            
            <p><strong>Visual simulation beats direct questioning:</strong> The visual cue approach in both methods was transformative. Rather than asking users to describe hypothetical experiences, presenting concrete scenarios allowed them to evaluate and react—producing far richer insights.</p>

            <h2>Conclusion</h2>
            <p>While specific project outcomes remain confidential, the development and application of the "Time Loop" and "Feeling Cues" methods provided valuable frameworks for exploring future-facing user needs in a nuanced way.</p>

            <p>These methods allowed us to move beyond current usage patterns and delve into how Facebook Home could proactively integrate into users' lives based on temporal context and emotional state, generating rich qualitative data even when exploring abstract future possibilities. They represent adaptable techniques for generative research in product development.</p>

            <!-- Skills Demonstrated -->
            <div class="key-finding" style="margin-top: 3rem;">
                <h4>Skills & Methods Demonstrated</h4>
                <p><strong>Research:</strong> Generative Research • Method Development • Semi-Structured Interviews • User Research • Insight Synthesis</p>
                <p><strong>Design:</strong> Conceptual Design • Prototyping • Figma • UX Writing • Co-Design Workshops</p>
                <p><strong>Innovation:</strong> Novel Method Creation • Research Strategy • Future-Focused Research • Pattern Recognition</p>
                <p><strong>Impact:</strong> Stakeholder Presentation • Product Strategy • Cross-Functional Collaboration</p>
            </div>

        </div>

        <footer class="footer">
            <p>&copy; 2024 Sai Maram. Case Study.</p>
            <p><a href="./index.html">Back to Portfolio</a></p>
        </footer>
    </main>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const portfolioToggle = document.getElementById('portfolio-toggle');
            const projectLinksContainer = document.getElementById('project-links-container');
            const portfolioIndicator = document.getElementById('portfolio-indicator'); 

            if (portfolioToggle) {
                portfolioToggle.addEventListener('click', function() {
                    projectLinksContainer.classList.toggle('hidden');
                    if (projectLinksContainer.classList.contains('hidden')) {
                        portfolioIndicator.textContent = '+';
                    } else {
                        portfolioIndicator.textContent = '-';
                    }
                });
            }
        });

        function showLockedMessage() {
            alert("This case study is under NDA and cannot be shared publicly. Please contact me directly for more information about my work at Microsoft/Xbox.");
        }

        function showComingSoon() {
            alert("This project case study is currently being developed. Please check back soon!");
        }
    </script>
</body>
</html>